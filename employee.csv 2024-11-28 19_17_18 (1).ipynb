{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58a80d9a-8d39-44b9-9740-754416749aea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+----------+------+----------+\n| id|   name|age|department|salary| join_date|\n+---+-------+---+----------+------+----------+\n|  1|   John| 34|        IT| 75000|2015-06-01|\n|  2|   Sara| 28|        HR| 58000|2019-09-15|\n|  3|Michael| 45|   Finance|120000|2010-01-10|\n|  4|  Karen| 29|        IT| 70000|2020-02-19|\n|  5|  David| 38|   Finance| 90000|2017-08-23|\n|  6|  Linda| 33|        HR| 60000|2018-12-05|\n|  7|  James| 41|        IT|110000|2013-04-15|\n|  8|  Emily| 27|        HR| 52000|2021-06-20|\n|  9| Robert| 36|   Finance|105000|2016-11-30|\n+---+-------+---+----------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Start a Spark session\n",
    "spark = SparkSession.builder.appName(\"EmployeeAnalysis\").getOrCreate()\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"/FileStore/tables/employe-1.csv\"  \n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "266a88d2-d57f-4946-8d85-d0ec064f1644",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+----------+------+----------+\n| id|   name|age|department|salary| join_date|\n+---+-------+---+----------+------+----------+\n|  1|   John| 34|        IT| 75000|2015-06-01|\n|  3|Michael| 45|   Finance|120000|2010-01-10|\n|  5|  David| 38|   Finance| 90000|2017-08-23|\n|  6|  Linda| 33|        HR| 60000|2018-12-05|\n|  7|  James| 41|        IT|110000|2013-04-15|\n|  9| Robert| 36|   Finance|105000|2016-11-30|\n+---+-------+---+----------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.age > 30).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df00fbf1-443c-4e98-8901-0bbfe3605300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n|department|        avg_salary|\n+----------+------------------+\n|        HR|56666.666666666664|\n|   Finance|          105000.0|\n|        IT|           85000.0|\n+----------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"department\").agg(avg(\"salary\").alias(\"avg_salary\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7374ec3-029b-4439-96cb-e54dcc3c1181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+----------+------+----------+----------+\n| id|   name|age|department|salary| join_date|experience|\n+---+-------+---+----------+------+----------+----------+\n|  1|   John| 34|        IT| 75000|2015-06-01|         9|\n|  2|   Sara| 28|        HR| 58000|2019-09-15|         5|\n|  3|Michael| 45|   Finance|120000|2010-01-10|        14|\n|  4|  Karen| 29|        IT| 70000|2020-02-19|         4|\n|  5|  David| 38|   Finance| 90000|2017-08-23|         7|\n|  6|  Linda| 33|        HR| 60000|2018-12-05|         5|\n|  7|  James| 41|        IT|110000|2013-04-15|        11|\n|  8|  Emily| 27|        HR| 52000|2021-06-20|         3|\n|  9| Robert| 36|   Finance|105000|2016-11-30|         8|\n+---+-------+---+----------+------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date, datediff\n",
    "\n",
    "df = df.withColumn(\"experience\", (datediff(current_date(), col(\"join_date\")) / 365).cast(\"int\"))\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f49662a4-43fc-48e6-8aac-3d3b05cd739b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+----------+------+----------+----------+\n| id|   name|age|department|salary| join_date|experience|\n+---+-------+---+----------+------+----------+----------+\n|  3|Michael| 45|   Finance|120000|2010-01-10|        14|\n|  7|  James| 41|        IT|110000|2013-04-15|        11|\n|  9| Robert| 36|   Finance|105000|2016-11-30|         8|\n+---+-------+---+----------+------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col(\"salary\").desc()).limit(3).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a591383-965e-4052-a744-fb123ae2e103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n|department|total_salary|\n+----------+------------+\n|   Finance|      315000|\n+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"department\").agg(sum(\"salary\").alias(\"total_salary\")) \\\n",
    "  .orderBy(col(\"total_salary\").desc()).limit(1).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf874c67-e54e-45bf-8134-c2425aa13738",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+----------+------+----------+----------+\n| id|   name|age|department|salary| join_date|experience|\n+---+-------+---+----------+------+----------+----------+\n|  3|Michael| 45|   Finance|120000|2010-01-10|        14|\n|  5|  David| 38|   Finance| 90000|2017-08-23|         7|\n|  7|  James| 41|        IT|110000|2013-04-15|        11|\n|  9| Robert| 36|   Finance|105000|2016-11-30|         8|\n+---+-------+---+----------+------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "avg_salary = df.select(avg(\"salary\").alias(\"avg_salary\")).collect()[0][\"avg_salary\"]\n",
    "df.filter(df.salary > avg_salary).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9de30c31-8623-4b4a-bc19-d5ce146b8993",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+----------+------+----------+----------+\n| id|employee_name|age|department|salary| join_date|experience|\n+---+-------------+---+----------+------+----------+----------+\n|  1|         John| 34|        IT| 75000|2015-06-01|         9|\n|  2|         Sara| 28|        HR| 58000|2019-09-15|         5|\n|  3|      Michael| 45|   Finance|120000|2010-01-10|        14|\n|  4|        Karen| 29|        IT| 70000|2020-02-19|         4|\n|  5|        David| 38|   Finance| 90000|2017-08-23|         7|\n|  6|        Linda| 33|        HR| 60000|2018-12-05|         5|\n|  7|        James| 41|        IT|110000|2013-04-15|        11|\n|  8|        Emily| 27|        HR| 52000|2021-06-20|         3|\n|  9|       Robert| 36|   Finance|105000|2016-11-30|         8|\n+---+-------------+---+----------+------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed(\"name\", \"employee_name\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f14c6197-d35f-4e44-8d77-07b075a17f55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n|department|count|\n+----------+-----+\n|        HR|    3|\n|   Finance|    3|\n|        IT|    3|\n+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"department\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22f29499-cfe1-4c2b-bb5c-134e002649cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n| id|employee_name|\n+---+-------------+\n|  1|         John|\n|  2|         Sara|\n|  3|      Michael|\n|  4|        Karen|\n|  5|        David|\n|  6|        Linda|\n|  7|        James|\n|  8|        Emily|\n|  9|       Robert|\n+---+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"id\", \"employee_name\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdb85a64-beef-4a32-a0af-b426668a6b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+----------+------+---------+----------+\n| id|employee_name|age|department|salary|join_date|experience|\n+---+-------------+---+----------+------+---------+----------+\n|  0|            0|  0|         0|     0|        0|         0|\n+---+-------------+---+----------+------+---------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "employee.csv 2024-11-28 19:17:18",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
